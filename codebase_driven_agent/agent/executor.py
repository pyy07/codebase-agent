"""Agent ÊâßË°åÂô®ÂÆûÁé∞"""
import asyncio
import json
from typing import List, Optional, Dict, Any
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

from codebase_driven_agent.agent.prompt import generate_system_prompt
from codebase_driven_agent.agent.memory import AgentMemory
from codebase_driven_agent.tools import CodeTool, LogTool, DatabaseTool
from codebase_driven_agent.utils.database import get_schema_info, format_schema_info
from codebase_driven_agent.config import settings
from codebase_driven_agent.utils.logger import setup_logger
from codebase_driven_agent.utils.metrics import record_agent_metrics

logger = setup_logger("codebase_driven_agent.agent.executor")

# ÂêØÁî® OpenAI ÂÆ¢Êà∑Á´ØÁöÑËØ¶ÁªÜÊó•Âøó
import logging
openai_logger = logging.getLogger("openai")
openai_logger.setLevel(logging.DEBUG)


def create_llm():
    """ÂàõÂª∫ LLM ÂÆû‰æã"""
    logger.info("Creating LLM instance...")
    logger.info("=" * 80)
    logger.info("Checking LLM Configuration:")
    logger.info(f"  LLM_BASE_URL: {settings.llm_base_url}")
    logger.info(f"  LLM_API_KEY: {'***' if settings.llm_api_key else 'None'}")
    logger.info(f"  OPENAI_BASE_URL: {settings.openai_base_url}")
    logger.info(f"  OPENAI_API_KEY: {'***' if settings.openai_api_key else 'None'}")
    logger.info(f"  LLM_MODEL: {settings.llm_model}")
    logger.info("=" * 80)
    
    # ‰ºòÂÖà‰ΩøÁî®Ëá™ÂÆö‰πâ Base URLÔºàÊîØÊåÅÂÖ∂‰ªñ‰æõÂ∫îÂïÜÔºâ
    if settings.llm_base_url and settings.llm_api_key:
        # ‰ΩøÁî®Ëá™ÂÆö‰πâ Base URLÔºàOpenAI ÂÖºÂÆπÊé•Âè£Ôºâ
        logger.info("=" * 80)
        logger.info("LLM Configuration:")
        logger.info(f"  Provider: Custom (using LLM_BASE_URL)")
        logger.info(f"  Base URL: {settings.llm_base_url}")
        logger.info(f"  Model: {settings.llm_model}")
        logger.info(f"  API Key: {settings.llm_api_key[:10]}...{settings.llm_api_key[-4:] if len(settings.llm_api_key) > 14 else '***'}")
        logger.info(f"  Temperature: {settings.llm_temperature}")
        logger.info(f"  Max Tokens: {settings.llm_max_tokens}")
        logger.info("=" * 80)
        llm = ChatOpenAI(
            model_name=settings.llm_model,
            temperature=settings.llm_temperature,
            max_tokens=settings.llm_max_tokens,
            api_key=settings.llm_api_key,
            base_url=settings.llm_base_url,
        )
        # ÊâìÂç∞ÂÆûÈôÖ‰ΩøÁî®ÁöÑÈÖçÁΩÆÂíåÂÆåÊï¥ÁöÑ API URL
        logger.info(f"  Actual Base URL (from client): {llm.openai_api_base if hasattr(llm, 'openai_api_base') else settings.llm_base_url}")
        logger.info(f"  Actual Model Name: {llm.model_name}")
        # ÊûÑÂª∫ÂÆåÊï¥ÁöÑ API URLÔºàLangChain ‰ºöËá™Âä®Ê∑ªÂä† /chat/completionsÔºâ
        full_api_url = f"{settings.llm_base_url.rstrip('/')}/chat/completions"
        logger.info(f"  Full API URL: {full_api_url}")
        logger.info(f"  Request will be sent to: POST {full_api_url}")
        logger.info(f"  Request headers will include: Authorization: Bearer {settings.llm_api_key[:10]}...{settings.llm_api_key[-4:] if len(settings.llm_api_key) > 14 else '***'}")
        return llm
    elif settings.openai_api_key:
        # ‰ΩøÁî® OpenAIÔºàÊîØÊåÅËá™ÂÆö‰πâ Base URLÔºâ
        base_url = settings.openai_base_url or "https://api.openai.com/v1"
        logger.info("=" * 80)
        logger.info("LLM Configuration:")
        logger.info(f"  Provider: OpenAI")
        logger.info(f"  Base URL: {base_url}")
        logger.info(f"  Model: {settings.llm_model}")
        logger.info(f"  API Key: {settings.openai_api_key[:10]}...{settings.openai_api_key[-4:] if len(settings.openai_api_key) > 14 else '***'}")
        logger.info(f"  Temperature: {settings.llm_temperature}")
        logger.info(f"  Max Tokens: {settings.llm_max_tokens}")
        logger.info("=" * 80)
        llm = ChatOpenAI(
            model_name=settings.llm_model,
            temperature=settings.llm_temperature,
            max_tokens=settings.llm_max_tokens,
            api_key=settings.openai_api_key,
            base_url=base_url,  # Â¶ÇÊûúËÆæÁΩÆ‰∫ÜËá™ÂÆö‰πâ Base URLÔºå‰ΩøÁî®ÂÆÉ
        )
        # ÊâìÂç∞ÂÆûÈôÖ‰ΩøÁî®ÁöÑÈÖçÁΩÆ
        logger.info(f"  Actual Base URL (from client): {llm.openai_api_base if hasattr(llm, 'openai_api_base') else base_url}")
        logger.info(f"  Actual Model Name: {llm.model_name}")
        # ÊûÑÂª∫ÂÆåÊï¥ÁöÑ API URLÔºàLangChain ‰ºöËá™Âä®Ê∑ªÂä† /chat/completionsÔºâ
        full_api_url = f"{base_url.rstrip('/')}/chat/completions"
        logger.info(f"  Full API URL: {full_api_url}")
        return llm
    elif settings.anthropic_api_key:
        logger.info("=" * 80)
        logger.info("LLM Configuration:")
        logger.info(f"  Provider: Anthropic")
        logger.info(f"  Model: {settings.llm_model}")
        logger.info(f"  API Key: {settings.anthropic_api_key[:10]}...{settings.anthropic_api_key[-4:] if len(settings.anthropic_api_key) > 14 else '***'}")
        logger.info(f"  Temperature: {settings.llm_temperature}")
        logger.info(f"  Max Tokens: {settings.llm_max_tokens}")
        logger.info("=" * 80)
        return ChatAnthropic(
            model=settings.llm_model if settings.llm_model.startswith("claude") else "claude-3-opus-20240229",
            temperature=settings.llm_temperature,
            max_tokens=settings.llm_max_tokens,
            api_key=settings.anthropic_api_key,
        )
    else:
        raise ValueError(
            "No LLM API key configured. Please set one of: "
            "OPENAI_API_KEY, ANTHROPIC_API_KEY, or LLM_API_KEY with LLM_BASE_URL"
        )


def get_tools() -> List:
    """Ëé∑ÂèñÊâÄÊúâÂ∑•ÂÖ∑ÂàóË°®ÔºàÊîØÊåÅÂä®ÊÄÅÊ≥®ÂÜåÔºâ"""
    logger.info("get_tools() called")
    # ‰ºòÂÖà‰ΩøÁî®Ê≥®ÂÜåË°®ÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
    try:
        logger.info("Trying to load tools from registry...")
        from codebase_driven_agent.tools.registry import get_tool_registry
        logger.info("Importing get_tool_registry...")
        registry = get_tool_registry()
        logger.info("Got tool registry, calling get_all_tools()...")
        tools = registry.get_all_tools()
        logger.info(f"Registry returned {len(tools)} tools")
        if tools:
            logger.info(f"Loaded {len(tools)} tools from registry: {[tool.name for tool in tools]}")
            return tools
        else:
            logger.warning("Registry returned empty tools list, falling back to manual registration")
    except Exception as e:
        logger.warning(f"Failed to load tools from registry: {str(e)}, falling back to manual registration", exc_info=True)
    
    # ÂõûÈÄÄÂà∞ÊâãÂä®Ê≥®ÂÜåÔºàÂêëÂêéÂÖºÂÆπÔºâ
    logger.info("Using manual tool registration fallback")
    tools = []
    
    # ‰ª£Á†ÅÂ∑•ÂÖ∑
    try:
        logger.debug("Initializing CodeTool...")
        code_tool = CodeTool()
        tools.append(code_tool)
        logger.debug("CodeTool initialized")
    except Exception as e:
        logger.warning(f"Failed to initialize CodeTool: {str(e)}")
    
    # Êó•ÂøóÂ∑•ÂÖ∑
    try:
        logger.debug("Initializing LogTool...")
        log_tool = LogTool()
        tools.append(log_tool)
        logger.debug("LogTool initialized")
    except Exception as e:
        logger.warning(f"Failed to initialize LogTool: {str(e)}")
    
    # Êï∞ÊçÆÂ∫ìÂ∑•ÂÖ∑ÔºàÂè™ÊúâÂú®ÈÖçÁΩÆ‰∫ÜÊï∞ÊçÆÂ∫ì URL Êó∂ÊâçÂàùÂßãÂåñÔºâ
    try:
        from codebase_driven_agent.config import settings
        if settings.database_url:
            logger.debug("Initializing DatabaseTool...")
            database_tool = DatabaseTool()
            tools.append(database_tool)
            logger.debug("DatabaseTool initialized")
        else:
            logger.debug("Database URL not configured, skipping DatabaseTool")
    except Exception as e:
        logger.warning(f"Failed to initialize DatabaseTool: {str(e)}")
    
    logger.info(f"Manual registration completed, total tools: {len(tools)}")
    if not tools:
        logger.error("No tools available! Agent will not be able to perform any actions.")
    
    return tools


def create_agent_executor(
    memory: Optional[AgentMemory] = None,
    max_iterations: Optional[int] = None,
    max_execution_time: Optional[int] = None,
    callbacks: Optional[List] = None,
):
    """
    ÂàõÂª∫ AgentÔºàLangChain 1.0+ ‰ΩøÁî® create_agentÔºâ
    
    Args:
        memory: Agent ËÆ∞ÂøÜÔºàÂèØÈÄâÔºâ
        max_iterations: ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞ÔºàÂèØÈÄâÔºåÈªòËÆ§‰ΩøÁî®ÈÖçÁΩÆÔºâ
        max_execution_time: ÊúÄÂ§ßÊâßË°åÊó∂Èó¥ÔºàÁßíÔºåÂèØÈÄâÔºåÈªòËÆ§‰ΩøÁî®ÈÖçÁΩÆÔºâ
        callbacks: ÂõûË∞ÉÂáΩÊï∞ÂàóË°®ÔºàÂèØÈÄâÔºâ
    
    Returns:
        Agent ÂÆû‰æãÔºàÂèØÁõ¥Êé•Ë∞ÉÁî® invoke ÊñπÊ≥ïÔºâ
    """
    logger.info("Creating agent executor...")
    
    # ÂàõÂª∫ LLM
    logger.info("Creating LLM instance...")
    llm = create_llm()
    logger.info(f"LLM created: {type(llm).__name__}")
    
    # Ëé∑ÂèñÂ∑•ÂÖ∑
    logger.info("Getting tools...")
    tools = get_tools()
    logger.info(f"Loaded {len(tools)} tools: {[tool.name for tool in tools]}")
    
    # Ëé∑Âèñ Schema ‰ø°ÊÅØÔºàÁî®‰∫éÊ≥®ÂÖ•Âà∞ PromptÔºâ
    logger.info("Getting database schema info...")
    try:
        schema_info = get_schema_info()
        logger.info(f"Schema info retrieved: {len(schema_info.get('tables', {}))} tables")
    except Exception as e:
        logger.warning(f"Failed to get schema info: {str(e)}")
        schema_info = {}
    schema_text = format_schema_info(schema_info) if schema_info else "No database schema available."
    logger.info(f"Schema text length: {len(schema_text)}")
    
    # Ê£ÄÊü•ÊòØÂê¶‰ΩøÁî®Êó•ÂøóÊòìÔºàÈúÄË¶ÅÊ∑ªÂä† SPL Êü•ËØ¢Á§∫‰æãÔºâ
    logger.info("Checking log query instance...")
    from codebase_driven_agent.utils.log_query import get_log_query_instance
    include_spl_examples = False
    try:
        log_query_instance = get_log_query_instance()
        # Ê£ÄÊü•ÊòØÂê¶ÊòØÊó•ÂøóÊòìÂÆûÁé∞
        from codebase_driven_agent.utils.log_query import LogyiLogQuery
        if isinstance(log_query_instance, LogyiLogQuery):
            include_spl_examples = True
            logger.info("Using Logyi log query, will include SPL examples")
    except Exception as e:
        # Â¶ÇÊûúÊó†Ê≥ïËé∑ÂèñÊó•ÂøóÊü•ËØ¢ÂÆû‰æãÔºåÂøΩÁï•
        logger.debug(f"Could not get log query instance: {str(e)}")
        pass
    
    # ÁîüÊàêÁ≥ªÁªüÊèêÁ§∫
    logger.debug("Generating system prompt...")
    tools_description = "\n".join([f"- {tool.name}: {tool.description}" for tool in tools])
    logger.debug(f"Tools description length: {len(tools_description)}")
    system_prompt = generate_system_prompt(
        tools_description=tools_description,
        schema_info=schema_text,
        include_spl_examples=include_spl_examples,
    )
    logger.debug(f"System prompt generated, length: {len(system_prompt)}")
    # ÊâìÂç∞ÂÆåÊï¥ÁöÑ promptÔºàdebug Á∫ßÂà´Ôºâ
    logger.debug("=" * 80)
    logger.debug("Full System Prompt:")
    logger.debug(system_prompt)
    logger.debug("=" * 80)
    
    # ‰ΩøÁî®Êñ∞ÁöÑ create_agent API (LangChain 1.0+)
    logger.info("Creating agent with LangChain create_agent API...")
    agent_runnable = create_agent(
        model=llm,
        tools=tools,
        system_prompt=system_prompt,
    )
    logger.info("Agent created successfully")
    
    # Âú® LangChain 1.0+ ‰∏≠Ôºåcreate_agent ËøîÂõûÁöÑ agent ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®
    # Â≠òÂÇ®ÈÖçÁΩÆ‰ø°ÊÅØ‰æõÂêéÁª≠‰ΩøÁî®
    agent_runnable._max_iterations = max_iterations or settings.agent_max_iterations
    agent_runnable._max_execution_time = max_execution_time or settings.agent_max_execution_time
    agent_runnable._callbacks = callbacks or []
    
    logger.info(f"Agent configured: max_iterations={agent_runnable._max_iterations}, max_execution_time={agent_runnable._max_execution_time}")
    
    return agent_runnable


class AgentExecutorWrapper:
    """Agent ÊâßË°åÂô®ÂåÖË£ÖÁ±ª"""
    
    def __init__(
        self,
        memory: Optional[AgentMemory] = None,
        max_iterations: Optional[int] = None,
        max_execution_time: Optional[int] = None,
        callbacks: Optional[List] = None,
    ):
        self.memory = memory or AgentMemory()
        self.callbacks = callbacks or []
        self.executor = create_agent_executor(
            memory=self.memory,
            max_iterations=max_iterations,
            max_execution_time=max_execution_time,
            callbacks=self.callbacks,
        )
    
    async def run(
        self,
        input_text: str,
        context_files: Optional[List[Dict[str, Any]]] = None,
        plan_steps: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        ÊâßË°å Agent ÂàÜÊûê
        
        Args:
            input_text: Áî®Êà∑ËæìÂÖ•
            context_files: ‰∏ä‰∏ãÊñáÊñá‰ª∂ÂàóË°®ÔºàÂèØÈÄâÔºâ
            plan_steps: ÂàÜÊûêËÆ°ÂàíÊ≠•È™§ÂàóË°®ÔºàÂèØÈÄâÔºâ
        
        Returns:
            ÊâßË°åÁªìÊûúÂ≠óÂÖ∏
        """
        import time
        start_time = time.time()
        
        try:
            logger.info(f"Agent execution started, input length: {len(input_text)}")
            
            # ÊûÑÂª∫ËæìÂÖ•ÔºàÂåÖÂê´‰∏ä‰∏ãÊñáÊñá‰ª∂‰ø°ÊÅØÂíåËÆ°ÂàíÔºâ
            full_input = input_text
            
            # Â¶ÇÊûúÊúâËÆ°ÂàíÊ≠•È™§ÔºåÂ∞ÜÂÖ∂ÂåÖÂê´Âú®ËæìÂÖ•‰∏≠
            if plan_steps:
                plan_text = "\n\n## üìã ÂàÜÊûêËÆ°ÂàíÔºàËØ∑‰∏•Ê†ºÊåâÁÖßÊ≠§ËÆ°ÂàíÊâßË°åÔºâ\n\n"
                for step in plan_steps:
                    step_num = step.get("step", 0)
                    action = step.get("action", "")
                    target = step.get("target", "")
                    if target:
                        plan_text += f"Ê≠•È™§ {step_num}: {action} - {target}\n"
                    else:
                        plan_text += f"Ê≠•È™§ {step_num}: {action}\n"
                plan_text += "\n**ÈáçË¶ÅÊèêÁ§∫**Ôºö\n"
                plan_text += "1. ËØ∑‰∏•Ê†ºÊåâÁÖß‰∏äËø∞ËÆ°ÂàíÊâßË°åÔºåÊåâÈ°∫Â∫èÂÆåÊàêÊØè‰∏™Ê≠•È™§\n"
                plan_text += "2. ÊØè‰∏™Ê≠•È™§ÂÆåÊàêÂêéÔºåÁªßÁª≠ÊâßË°å‰∏ã‰∏ÄÊ≠•Ôºå‰∏çË¶ÅË∑≥Ëøá\n"
                plan_text += "3. ‰ºòÂÖà‰ΩøÁî®‰ª£Á†ÅÂ∑•ÂÖ∑Ôºàcode_searchÔºâÊü•ÊâæÁõ∏ÂÖ≥‰ª£Á†ÅÔºåÂõ†‰∏∫‰ª£Á†ÅÊòØÈóÆÈ¢òÁöÑÊ†πÊ∫ê\n"
                plan_text += "4. Â¶ÇÊûúÊüê‰∏™Ê≠•È™§Â§±Ë¥•ÔºåÂ∞ùËØïÂÖ∂‰ªñÊñπÊ≥ïÔºå‰ΩÜ‰∏çË¶ÅË∑≥ËøáËÆ°Âàí‰∏≠ÁöÑÊ≠•È™§\n"
                plan_text += "5. ÂÆåÊàêÊâÄÊúâÊ≠•È™§ÂêéÔºåÁªôÂá∫ÂÆåÊï¥ÁöÑÂàÜÊûêÁªìËÆ∫\n"
                full_input = f"{input_text}{plan_text}"
                logger.info(f"Plan steps included in input: {len(plan_steps)} steps")
            
            # Ê∑ªÂä†‰∏ä‰∏ãÊñáÊñá‰ª∂‰ø°ÊÅØ
            if context_files:
                logger.info(f"Processing {len(context_files)} context files")
                context_info = self._format_context_files(context_files)
                full_input = f"{full_input}\n\nAdditional Context:\n{context_info}"
            
            logger.info(f"Prepared input, total length: {len(full_input)}")
            
            # ÊâßË°å Agent (LangChain 1.0+ ‰ΩøÁî® messages Ê†ºÂºè)
            # Callbacks ÈúÄË¶ÅÂú®Ë∞ÉÁî®Êó∂‰º†ÈÄí
            input_data = {
                "messages": [
                    {"role": "user", "content": full_input}
                ]
            }
            # Â¶ÇÊûúÊúâ callbacksÔºåÊ∑ªÂä†Âà∞ config ‰∏≠
            # ÂêåÊó∂‰º†ÈÄí max_iterations ÈÖçÁΩÆÔºàLangChain 1.0+ ÊîØÊåÅÈÄöËøá config ‰º†ÈÄíÔºâ
            config = {}
            if self.callbacks:
                config["callbacks"] = self.callbacks
                logger.info(f"Using {len(self.callbacks)} callback handlers")
            
            # ‰º†ÈÄí max_iterations ÈÖçÁΩÆ
            if hasattr(self.executor, '_max_iterations'):
                config["max_iterations"] = self.executor._max_iterations
                logger.info(f"Setting max_iterations={config['max_iterations']}")

            # ÊâìÂç∞ËØ∑Ê±Ç‰ø°ÊÅØÔºàÁî®‰∫éË∞ÉËØïÔºâ
            logger.info("=" * 80)
            logger.info("LLM Request Details:")
            logger.info(f"  Model: {settings.llm_model}")
            logger.info(f"  Base URL: {settings.llm_base_url or settings.openai_base_url or 'https://api.openai.com/v1'}")
            logger.info(f"  Temperature: {settings.llm_temperature}")
            logger.info(f"  Max Tokens: {settings.llm_max_tokens}")
            logger.info(f"  Input Length: {len(full_input)} characters")
            logger.info(f"  Input Preview (first 500 chars): {full_input[:500]}...")
            logger.info("=" * 80)
            
            # Âú®Ë∞ÉÁî®‰πãÂâçÊ£ÄÊü•ÊòØÂê¶Â∑≤ÂèñÊ∂à
            for callback in self.callbacks:
                if hasattr(callback, 'is_cancelled') and callback.is_cancelled():
                    logger.warning("Task already cancelled before LLM call, exiting immediately")
                    raise asyncio.CancelledError("Task has been cancelled")
            
            logger.info("Invoking agent executor (this may take a while for LLM calls)...")
            
            # ÂàõÂª∫‰∏Ä‰∏™ÂåÖË£ÖÂáΩÊï∞ÔºåÂú®Ë∞ÉÁî®ÂâçÊ£ÄÊü•ÂèñÊ∂àÁä∂ÊÄÅ
            def invoke_with_cancel_check():
                """ÂåÖË£Ö invoke Ë∞ÉÁî®ÔºåÂú®ÊâßË°åÂâçÊ£ÄÊü•ÂèñÊ∂àÁä∂ÊÄÅ"""
                # Ê£ÄÊü•ÊòØÂê¶Â∑≤ÂèñÊ∂àÔºåÂ¶ÇÊûúÂ∑≤ÂèñÊ∂àÔºåÁõ¥Êé•ÈÄÄÂá∫
                for callback in self.callbacks:
                    if hasattr(callback, 'is_cancelled') and callback.is_cancelled():
                        logger.warning("Task cancelled before invoke, exiting immediately")
                        # Áõ¥Êé•ÊäõÂá∫ CancelledErrorÔºåËÆ©‰∏äÂ±ÇÂ§ÑÁêÜ
                        raise KeyboardInterrupt("Task has been cancelled")
                
                # ÊâßË°å invoke
                return self.executor.invoke(input_data, config=config if config else None)
            
            try:
                logger.info("Starting asyncio.to_thread for executor.invoke...")
                # Ê∑ªÂä†Ë∂ÖÊó∂‰øùÊä§ÔºåÈÅøÂÖç LLM Ë∞ÉÁî®Êó†ÈôêÊúüÈòªÂ°û
                max_execution_time = self.executor._max_execution_time if hasattr(self.executor, '_max_execution_time') else 300
                logger.info(f"LLM call timeout set to {max_execution_time} seconds")
                
                # ‰ΩøÁî® asyncio.to_thread Âú®Á∫øÁ®ãÊ±†‰∏≠ÊâßË°åÂêåÊ≠•ÁöÑ invoke Ë∞ÉÁî®
                # ‰ΩøÁî® wait_for Êù•Á°Æ‰øùË∂ÖÊó∂ÂíåÂèñÊ∂àËÉΩÂ§üÁîüÊïà
                result = await asyncio.wait_for(
                    asyncio.to_thread(invoke_with_cancel_check),
                    timeout=max_execution_time
                )
                logger.info("asyncio.to_thread completed, got result")
            except asyncio.TimeoutError:
                logger.error(f"LLM call timed out after {max_execution_time} seconds")
                raise TimeoutError(f"Agent execution timed out after {max_execution_time} seconds")
            except asyncio.CancelledError:
                logger.warning("Agent executor was cancelled, exiting immediately")
                # ÈÄöÁü•ÊâÄÊúâ callback handler ‰ªªÂä°Â∑≤Ë¢´ÂèñÊ∂à
                for callback in self.callbacks:
                    if hasattr(callback, 'set_cancelled'):
                        try:
                            callback.set_cancelled()
                        except Exception as e:
                            logger.debug(f"Failed to set cancelled on callback: {e}")
                # ÈáçÊñ∞ÊäõÂá∫ CancelledErrorÔºåÁ´ãÂç≥ÈÄÄÂá∫
                raise
            except KeyboardInterrupt:
                # Â¶ÇÊûúÊòØÂú®Á∫øÁ®ã‰∏≠Ê£ÄÊµãÂà∞ÂèñÊ∂àÔºåËΩ¨Êç¢‰∏∫ CancelledError
                logger.warning("KeyboardInterrupt caught in thread, exiting immediately")
                raise asyncio.CancelledError("Task cancelled") from None
            except Exception as e:
                error_msg = str(e)
                # Â§ÑÁêÜÂ∏∏ËßÅÁöÑ LLM API ÈîôËØØÔºåÊèê‰æõÊõ¥ÂèãÂ•ΩÁöÑÈîôËØØ‰ø°ÊÅØ
                if "502" in error_msg or "Bad Gateway" in error_msg:
                    error_msg = "LLM API ÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®Ôºà502 Bad GatewayÔºâÔºåËØ∑Á®çÂêéÈáçËØï„ÄÇËøôÂèØËÉΩÊòØÊúçÂä°Á´ØÈóÆÈ¢òÊàñÁΩëÁªúÈóÆÈ¢ò„ÄÇ"
                elif "401" in error_msg or "Unauthorized" in error_msg:
                    error_msg = "LLM API ËÆ§ËØÅÂ§±Ë¥•Ôºà401 UnauthorizedÔºâÔºåËØ∑Ê£ÄÊü• API Key ÈÖçÁΩÆ„ÄÇ"
                elif "429" in error_msg or "rate limit" in error_msg.lower():
                    error_msg = "LLM API ËØ∑Ê±ÇÈ¢ëÁéáËøáÈ´òÔºà429 Rate LimitÔºâÔºåËØ∑Á®çÂêéÈáçËØï„ÄÇ"
                elif "timeout" in error_msg.lower():
                    error_msg = f"LLM API ËØ∑Ê±ÇË∂ÖÊó∂ÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúËøûÊé•ÊàñÁ®çÂêéÈáçËØï„ÄÇÂéüÂßãÈîôËØØÔºö{error_msg}"
                elif "503" in error_msg or "Service Unavailable" in error_msg:
                    error_msg = "LLM API ÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®Ôºà503 Service UnavailableÔºâÔºåËØ∑Á®çÂêéÈáçËØï„ÄÇ"
                
                logger.error(f"Error in executor.invoke: {error_msg}", exc_info=True)
                raise Exception(error_msg) from e
            
            logger.info("Agent executor completed successfully")
            
            execution_time = time.time() - start_time
            logger.info(f"Agent execution took {execution_time:.2f} seconds")
            
            # LangChain 1.0+ ËøîÂõûÊ†ºÂºè: {"messages": [...]}
            # ÊèêÂèñÊúÄÂêé‰∏ÄÊù°Ê∂àÊÅØ‰Ωú‰∏∫ËæìÂá∫
            if isinstance(result, dict) and "messages" in result:
                messages = result["messages"]
                logger.info(f"Processing {len(messages)} messages from agent")
                # Êü•ÊâæÊúÄÂêé‰∏ÄÊù° AI Ê∂àÊÅØ
                output = ""
                tool_calls = 0
                for msg in reversed(messages):
                    if hasattr(msg, "content") and msg.content:
                        output = msg.content
                        break
                    elif isinstance(msg, dict) and msg.get("content"):
                        output = msg["content"]
                        break
                    # ÁªüËÆ°Â∑•ÂÖ∑Ë∞ÉÁî®
                    if hasattr(msg, "tool_calls") or (isinstance(msg, dict) and "tool_calls" in msg):
                        tool_calls += 1
            else:
                output = str(result) if result else ""
                tool_calls = 0
                logger.warning(f"Unexpected result format: {type(result)}")
            
            logger.info(f"Extracted output length: {len(output)}, tool calls: {tool_calls}")
            
            # ËÆ∞ÂΩïÊåáÊ†á
            record_agent_metrics(execution_time, tool_calls, success=True)
            
            return {
                "success": True,
                "output": output,
                "intermediate_steps": result.get("messages", []) if isinstance(result, dict) else [],
            }
        
        except Exception as e:
            execution_time = time.time() - start_time
            tool_calls = 0
            
            # ËÆ∞ÂΩïÈîôËØØÊåáÊ†á
            record_agent_metrics(execution_time, tool_calls, success=False)
            
            logger.error(f"Agent execution failed: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "output": None,
                "intermediate_steps": [],
            }
    
    def _format_context_files(self, context_files: List[Dict[str, Any]]) -> str:
        """Ê†ºÂºèÂåñ‰∏ä‰∏ãÊñáÊñá‰ª∂‰ø°ÊÅØ"""
        formatted = []
        for ctx_file in context_files:
            if ctx_file.get("type") == "code":
                formatted.append(
                    f"Code file: {ctx_file.get('path', 'unknown')}\n"
                    f"Lines: {ctx_file.get('line_start', '?')}-{ctx_file.get('line_end', '?')}\n"
                    f"Content:\n{ctx_file.get('content', '')}\n"
                )
            elif ctx_file.get("type") == "log":
                formatted.append(
                    f"Log file: {ctx_file.get('path', 'unknown')}\n"
                    f"Content:\n{ctx_file.get('content', '')}\n"
                )
        
        return "\n---\n".join(formatted)

